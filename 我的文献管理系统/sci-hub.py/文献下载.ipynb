{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import requests\n",
    "from lxml import etree\n",
    "from contextlib import closing\n",
    "from tqdm import tqdm\n",
    "from lxml.html import fromstring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import etree\n",
    "from contextlib import closing\n",
    "from tqdm import tqdm \n",
    "from urllib.request import urlopen\n",
    "urlopen('https://www.howsmyssl.com/a/check').read()\n",
    "\n",
    "scihubUrl=\"https://sci-hub.se/\"\n",
    "\n",
    "with open('/Users/mac/myPrograme/literatureManage/sci-hub.py/mydoi.txt', \"r\") as doi:\n",
    "    doilist = doi.readlines()\n",
    "    doilist = list(map(lambda x: x.rstrip(\"\\n\"), doilist))\n",
    "n=1\n",
    "for doi in doilist[:1]:\n",
    "    req = requests.get(url=scihubUrl+doi)\n",
    "    root = etree.HTML(req.content)\n",
    "    elementDownloadLink = root.xpath(\"//*[@id='pdf']/@src\")[0]\n",
    "    reqFile = requests.get(url=\"https:\"+elementDownloadLink, stream=True)\n",
    "\n",
    "    try:\n",
    "        fileName = doi.replace(\"/\", \".\")+\".pdf\"\n",
    "        with closing(reqFile) as response:\n",
    "            with open(fileName, \"wb\") as file:\n",
    "                file.write(reqFile.content)\n",
    "                print(n+\"is done\")\n",
    "    except:\n",
    "        print('err')\n",
    "    n+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:  https://sci-hub.se/10.1038/srep4088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/.pyenv/versions/3.7.3/lib/python3.7/site-packages/urllib3/connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error occurred:  name 'proxies' is not defined\n",
      "Downloading:  None\n",
      "Download error Invalid URL 'None': No schema supplied. Perhaps you meant http://None?\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml.html import fromstring\n",
    "from lxml import etree\n",
    "\n",
    "from urllib.request import urlopen\n",
    "urlopen('https://www.howsmyssl.com/a/check').read()\n",
    "\n",
    "def download(doi, user_agent=\"sheng\", proxies=None, num_retries=2, start_url='sci-hub.se'):\n",
    "    headers = {'User-Agent': user_agent}\n",
    "    url = 'https://{}/{}'.format(start_url, doi)\n",
    "    print('Downloading: ', url)\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, proxies=proxies, verify=False)\n",
    "        html = resp.text\n",
    "        if resp.status_code >= 400:\n",
    "            print('Download error: ', resp.text)\n",
    "            html = None\n",
    "            if num_retries and 500 <= resp.status_code < 600:\n",
    "                return download(url, user_agent, proxies, num_retries-1)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print('Download error', e)\n",
    "        return None\n",
    "    return html \n",
    "\n",
    "def get_link_xpath(html):\n",
    "    try:\n",
    "#         tree = fromstring(html)\n",
    "#         a = tree.xpath('//div[@id=\"buttons\"]/ul/li/a')[0]  # 区别\n",
    "#         onclick = a.get('onclick')\n",
    "# #         print(onclick)\n",
    "#         return onclick.replace(\"location.href='\",\"https:\")[:-1]\n",
    "        resp = requests.get(url, headers=headers, proxies=proxies, verify=False)\n",
    "        root = etree.HTML(resp.content)\n",
    "        return root.xpath(\"//*[@id='pdf']/@src\")[0]\n",
    "    except Exception as e:\n",
    "        print('error occurred: ', e)\n",
    "        return None\n",
    "\n",
    "def download_pdf(url, user_agent=\"sheng\", proxies=None, num_retries=2):\n",
    "    headers = {'User-Agent': user_agent}\n",
    "#     url = 'https:{}'.format(url)  # 改动1\n",
    "    print('Downloading: ', url)\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, proxies=proxies, verify=False)\n",
    "        if resp.status_code >= 400:\n",
    "            print('Download error: ', resp.status_code)\n",
    "            if num_retries and 500 <= resp.status_code < 600:\n",
    "                return download(url, user_agent, proxies, num_retries-1)\n",
    "        #  ok, let's write it to file\n",
    "        with open('file.pdf', 'wb') as fp:  # 改动2，注意 'wb' 而不是 'w'\n",
    "            fp.write(resp.content)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print('Download error', e)\n",
    "#  简单的测试\n",
    "if __name__ == '__main__':\n",
    "    doi = '10.1038/srep4088'\n",
    "    html = download(doi)  # 获取文献资源网页的 html 文本\n",
    "#     from scraping_using_lxml import get_link_xpath\n",
    "    url = get_link_xpath(html)  # 提取下载链接\n",
    "    download_pdf(url)  # 执行下载\n",
    "    print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading:  https://sci-hub.se/10.1111.jofi.12497\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml.html import fromstring\n",
    "\n",
    "# from urllib.request import urlopen\n",
    "# urlopen('https://www.howsmyssl.com/a/check').read()\n",
    "\n",
    "def download(doi, user_agent=\"sheng\", proxies=None, num_retries=2, start_url='sci-hub.se'):\n",
    "    headers = {'User-Agent': user_agent}\n",
    "    url = 'https://{}/{}'.format(start_url, doi)\n",
    "    print('Downloading: ', url)\n",
    "    try:\n",
    "        resp = requests.get(url, headers=headers, proxies=proxies, verify=False)\n",
    "        html = resp.text\n",
    "        if resp.status_code >= 400:\n",
    "            print('Download error: ', resp.text)\n",
    "            html = None\n",
    "            if num_retries and 500 <= resp.status_code < 600:\n",
    "                return download(url, user_agent, proxies, num_retries-1)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print('Download error', e)\n",
    "        return None\n",
    "    return html \n",
    "doi = '10.1111.jofi.12497'\n",
    "html = download(doi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ParserError",
     "evalue": "Document is empty",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-04fdf571bd15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'//div[@id=\"buttons\"]/ul/li/a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# 区别\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0monclick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'onclick'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0monclick\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/lxml/html/__init__.py\u001b[0m in \u001b[0;36mfromstring\u001b[0;34m(html, base_url, parser, **kw)\u001b[0m\n\u001b[1;32m    873\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m         \u001b[0mis_full_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_looks_like_full_html_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 875\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocument_fromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    876\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_full_html\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.3/lib/python3.7/site-packages/lxml/html/__init__.py\u001b[0m in \u001b[0;36mdocument_fromstring\u001b[0;34m(html, parser, ensure_head_body, **kw)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         raise etree.ParserError(\n\u001b[0;32m--> 764\u001b[0;31m             \"Document is empty\")\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_head_body\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'head'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mElement\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'head'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Document is empty"
     ]
    }
   ],
   "source": [
    "tree = fromstring(html)\n",
    "a = tree.xpath('//div[@id=\"buttons\"]/ul/li/a')[0]  # 区别\n",
    "onclick = a.get('onclick')\n",
    "onclick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://sci-hub.se/downloads/2020-09-20/bb/zehri2020.pdf?download=true'"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "onclick.replace(\"location.href='\",\"https:\")[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "url=\"https://sci-hub.se/10.1002/ijfe.2182\"\n",
    "user_agent=\"sheng\"\n",
    "headers = {'User-Agent': user_agent}\n",
    "resp = requests.get(url, headers=headers, verify=False)\n",
    "html = resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/.pyenv/versions/3.7.3/lib/python3.7/site-packages/urllib3/connectionpool.py:1004: InsecureRequestWarning: Unverified HTTPS request is being made to host '127.0.0.1'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url=\"https://sci-hub.se/10.1002/ijfe.179\"\n",
    "user_agent=\"sheng\"\n",
    "headers = {'User-Agent': user_agent}\n",
    "resp = requests.get(url, headers=headers, verify=False)\n",
    "html = resp.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://sci-hub.se/downloads/2020-09-20/bb/zehri2020.pdf?download=true'"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "tree = fromstring(resp.content)\n",
    "a = tree.xpath('//div[@id=\"buttons\"]/ul/li/a')[0]  # 区别\n",
    "onclick = a.get('onclick')\n",
    "onclick.replace(\"location.href='\",\"https:\")[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://sci-hub.se/downloads/2020-09-20/bb/zehri2020.pdf?download=true'"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "root = etree.HTML(resp.content).xpath(\"//*[@id='pdf']/@src\")[0]\n",
    "\"https:\"+root[:-10]+\"?download=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'https://zero.sci-hub.se/6332/c94a27705412c864cae1b2a88dd66553/huang2017.pdf#view=FitH'"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "\n",
    "url=\"https://sci-hub.se/10.1007/s10600-017-1961-z\"\n",
    "user_agent=\"sheng\"\n",
    "headers = {'User-Agent': user_agent}\n",
    "resp = requests.get(url, headers=headers, verify=False)\n",
    "html = resp.text\n",
    "\n",
    "root = etree.HTML(resp.content).xpath(\"//*[@id='pdf']/@src\")[0]\n",
    "# root[:-10]+\"?download=true\"\n",
    "root "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/mac/myPrograme/literatureManage/sci-hub.py/mydoi.txt', \"r\") as doi:\n",
    "    doilist = doi.readlines()\n",
    "    doilist = list(map(lambda x: x.rstrip(\"\\n\"), doilist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[\"https://sci-hub.se/\"+i for i in doilist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1 http://sci-hub.se/downloads/2020-09-20/bb/zehri2020.pdf?download=true\n",
      "2 http://sci-hub.se/downloads/2019-11-19/bf/pandey2019.pdf?download=true\n",
      "3 http://sci-hub.se/downloads/2020-10-19/b2/li2020.pdf?download=true\n",
      "4 http://sci-hub.se/downloads/2020-10-19/b2/li2020.pdf?download=true\n",
      "5 https://zero.sci-hub.se/1843/572cf122588900165cf3d99d73d23e9a/schaling2009.pdf?download=true\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# url=\"https://sci-hub.se/10.1111/j.1468-0084.2011.00677.x\"\n",
    "with open('/Users/mac/myPrograme/literatureManage/sci-hub.py/mydoi.txt', \"r\") as doi:\n",
    "    doilist = doi.readlines()\n",
    "    doilist = list(map(lambda x: x.rstrip(\"\\n\"), doilist))\n",
    "urls=[\"https://sci-hub.se/\"+i for i in doilist]\n",
    "n=1\n",
    "for url in urls[:5]:\n",
    "    user_agent=\"sheng\"\n",
    "    headers = {'User-Agent': user_agent}\n",
    "    resp = requests.get(url, headers=headers, verify=False)\n",
    "    html = resp.text\n",
    "\n",
    "    try:\n",
    "        root = etree.HTML(resp.content).xpath(\"//*[@id='pdf']/@src\")[0]\n",
    "    except:\n",
    "        pass\n",
    "    URL=\"https:\"+root[:-10]+\"?download=true\"\n",
    "    print(n,URL.replace(\"https:https:\",\"https:\",))\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "url=\"https://sci-hub.se/10.1111/roie.1252\"\n",
    "user_agent=\"sheng\"\n",
    "headers = {'User-Agent': user_agent}\n",
    "resp = requests.get(url, headers=headers, verify=False)\n",
    "html = resp.text\n",
    "\n",
    "root = etree.HTML(resp.content).xpath(\"//*[@id='pdf']/@src\")\n",
    "# root[:-10]+\"?download=true\"\n",
    "root "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}