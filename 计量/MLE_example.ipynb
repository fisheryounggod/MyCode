{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一个MLE的python范例\n",
    "作者：黄勔 2021年1月2日，2021年4月9日更新\n",
    "\n",
    "备注：\n",
    "1. 基于给学生的家庭作业，这里给出一个用python做极大似然估计的例子。叫做范例其实也有不妥，因为我自己才刚刚转到使用python语言做数据分析上来，还有很多东西没有弄明白。叫做learnig by doing可能更好。\n",
    "\n",
    "作业原题如下：\n",
    "We are going to use the example on page 13 of logit model. Suppose there are 50 models of cars, the true parameter of $\\rho=0.5$, $\\theta=-0.3$. The simulated data consists of 1000 consumers. Please write your code to estimate these two parameters and find the variance covariance matrix?\n",
    "\n",
    "2. 由于自己是从 R 和 Julia 用户转移而来，同时也不清楚 python的 最佳实践方式。借此机会尝试比较一下使用 R 方式和 Julia 方式哪种方式在 python 中更有效。即 R 方式为尽量使用矩阵和向量的运算，避免使用循环，这是 R 和 matlab 这样的矩阵语言比较好的实践方式。Julia 方式为在可以的时候尽量使用基于标量的循环，减少内存的占用，利用 Julia 本身的速度优势。当然 python 由于 numba 的存在，我在两种方式中都尝试用 numba 做JIT（just in time）的实时编译来提高 python 的速度。同时使用 autograd 来实现搜索时的自动微分。(发现无法同时使用 autograd 和 numba，在本例中，我使用 autograd 来提高 gradient 和 hessian 的精度，放弃 jit 加速。如果你知道如何把 autograd 和 numba jit 结合使用，请一定告诉我。)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先引入必要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import pandas as pd\n",
    "from autograd import grad, jacobian, hessian\n",
    "from scipy.optimize import minimize\n",
    "#from numba import jit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读入汽车和消费者的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cars = pd.read_csv(\"data_cars.csv\")\n",
    "data_cons = pd.read_csv(\"data_consumers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     M          I  choice\n",
      "0    7  35.065422       3\n",
      "1    6  31.391821      40\n",
      "2    2  10.267193      44\n",
      "3    7  35.081169      40\n",
      "4    2   9.103030      22\n",
      "..  ..        ...     ...\n",
      "995  1   4.156514      28\n",
      "996  5  23.336381      44\n",
      "997  4  20.661315      28\n",
      "998  3  14.506193      20\n",
      "999  3  16.137090      30\n",
      "\n",
      "[1000 rows x 3 columns]\n",
      "    model   SR         PP\n",
      "0       1  4.3  11.157731\n",
      "1       2  4.7  13.219156\n",
      "2       3  5.1  12.270740\n",
      "3       4  4.3  13.379698\n",
      "4       5  4.3  11.598031\n",
      "5       6  4.9  12.604224\n",
      "6       7  4.0  11.290917\n",
      "7       8  4.3  12.361849\n",
      "8       9  4.0  10.615555\n",
      "9      10  5.1  13.027972\n",
      "10     11  4.7  12.421642\n",
      "11     12  4.9  11.769282\n",
      "12     13  4.7  11.701297\n",
      "13     14  4.7  12.577615\n",
      "14     15  4.0  10.392503\n",
      "15     16  4.0  13.318082\n",
      "16     17  5.1  13.219362\n",
      "17     18  4.9  13.360677\n",
      "18     19  4.9  13.341525\n",
      "19     20  4.3  13.442825\n",
      "20     21  4.3  11.336404\n",
      "21     22  4.7  12.097588\n",
      "22     23  4.9  14.131405\n",
      "23     24  4.3  10.902734\n",
      "24     25  4.7  12.310997\n",
      "25     26  4.0   9.753728\n",
      "26     27  5.1  14.280536\n",
      "27     28  4.9  11.770757\n",
      "28     29  4.7   9.915638\n",
      "29     30  5.1  12.256792\n",
      "30     31  4.3  12.968846\n",
      "31     32  4.7  11.633599\n",
      "32     33  4.7  11.327406\n",
      "33     34  4.7  10.845773\n",
      "34     35  4.7  11.349681\n",
      "35     36  5.1  13.264214\n",
      "36     37  4.3   9.634744\n",
      "37     38  4.3  11.955609\n",
      "38     39  4.7  12.469727\n",
      "39     40  4.9  13.882402\n",
      "40     41  4.9  12.838945\n",
      "41     42  4.9  13.540270\n",
      "42     43  5.1  12.548375\n",
      "43     44  4.9  12.327139\n",
      "44     45  4.7  13.156844\n",
      "45     46  4.3  11.589115\n",
      "46     47  4.3  11.077506\n",
      "47     48  4.9  10.661234\n",
      "48     49  5.1  13.447945\n",
      "49     50  4.7  13.310292\n"
     ]
    }
   ],
   "source": [
    "print(data_cons)\n",
    "print(data_cars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用R语言的方式工作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "design matrix for consumers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_cons = data_cons[['M', 'I', 'choice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_cons['1/I'] = 1/mat_cons['I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_cons.drop('I', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_cons = mat_cons.reindex(columns=['M','1/I','choice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_cons = np.array(mat_cons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## design matrix for cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_cars = np.array(data_cars[['SR','PP']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为个体构造llk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llk_n_R(data_con_n, theta):\n",
    "    x_n = data_con_n[:2]\n",
    "    choice_n = int(data_con_n[2])\n",
    "    theta=np.array(theta)\n",
    "    VJ = np.exp((x_n*mat_cars*theta).sum(axis=1))\n",
    "    Pn = VJ[choice_n-1]/VJ.sum()\n",
    "    return np.log(Pn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为数据集构建llk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_llk_R(theta):\n",
    "    llk = 0\n",
    "    for row in mat_cons:\n",
    "        llk += llk_n_R(row, theta)\n",
    "    return -1*llk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始求极大值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用autograd生成neg_llk的gradient和hessian以备用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobian_  = jacobian(neg_llk_R)\n",
    "hessian_ = hessian(neg_llk_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_theta = [1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用%timeit来查看求极值需要的时间："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%timeit res1 = minimize(neg_llk_R, init_theta, method = 'BFGS', options={'disp': False}, jac = jacobian_)\n",
    "res1 = minimize(neg_llk_R, init_theta, method = 'BFGS', options={'disp': False}, jac = jacobian_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fun: 3731.130548040255\n",
      " hess_inv: array([[ 0.00111563, -0.00263741],\n",
      "       [-0.00263741,  0.08937729]])\n",
      "      jac: array([-1.46790770e-07,  1.01165806e-08])\n",
      "  message: 'Optimization terminated successfully.'\n",
      "     nfev: 11\n",
      "      nit: 8\n",
      "     njev: 11\n",
      "   status: 0\n",
      "  success: True\n",
      "        x: array([ 0.5374429 , -0.32865209])\n"
     ]
    }
   ],
   "source": [
    "print(res1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到$\\theta$的极大似然估计值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_mle = res1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta$ 的渐进方差协方差矩阵为$-\\boldsymbol{H}^{-1}/N$，我们用neg_llk在估计值处的$hessian/N$来估计$-\\boldsymbol{H}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_H_inv = np.linalg.inv(hessian_(theta_mle)/mat_cons.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_mat = neg_H_inv/mat_cons.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00110568 -0.00256991]\n",
      " [-0.00256991  0.08891964]]\n"
     ]
    }
   ],
   "source": [
    "print(var_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "var_mat对角线元素即$\\theta$的极大似然估计的渐进方差"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
